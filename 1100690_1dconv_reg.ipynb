{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1100690_1dconv_reg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xQInLdudJrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class _1100690_1dconv_reg(torch.nn.Module):\n",
        "  def __init__(self,batch_size,inputs, outputs):\n",
        "    super(_1100690_1dconv_reg,self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "\n",
        "    self.input_layer = Conv1d(inputs,batch_size,1)\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "    self.con_layer = Conv1d(batch_size,128,1)\n",
        "    self.con_layer1 = Conv1d(128,64,1)\n",
        "    self.flatten_layer = Flatten()\n",
        "    self.linear_layer = Linear(64,64)\n",
        "    self.output_layer = Linear(64,outputs)\n",
        "  \n",
        "  def feed(self,input):\n",
        "    input = input.reshape((self.batch_size,self.inputs,1))\n",
        "    output = relu(self.input_layer(input))\n",
        "    output = self.max_pooling_layer(output)\n",
        "    output = relu(self.con_layer(output))\n",
        "    output = relu(self.con_layer1(output))\n",
        "    output = self.flatten_layer(output)\n",
        "    output = self.linear_layer(output)\n",
        "    output = self.output_layer(output)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}